## Report of Plots
The plots attached show the results of the optimized algorithms for solving the TSP across different graph sizes. RNN consistently achieves the best, or lowest, total cost, outperforming both NN and NN2O. As graph size increases, the gap between the NN, NN2O, and RNN solutions widen, which shows how effective 2-Opt and randomized selection are for larger graphs. Also, NN2O improves over NN but it doesn't outperform RNN. While NN is the fastest and computationally cheaper, it produces suboptimal results, and NN2O offers a balance between speed and cost. RNN is slower due to its optimization steps and multiple starting points, but is the most cost-effective, especially on larger graphs. It is important to note that CPU runtime measures the actual processing time, while real-world runtime includes all delays, so there might be a difference between the two based on factors like system load. Varying the 'n' value in RNN impacts both cost and runtime, with an optimal balance found at the “middle” value of ‘n’, after which performance declines. For example, when I tested RNN with the ‘n’ values [1, 2, 3, 4, 5], the ‘n’ that gave the best value was 3. A higher n did increase the chances of finding a better solution but also increased the runtime. From these findings, I can conclude that RNN is preferable when the goal is to minimize cost, and NN and NN2O are better for faster but less optimal results. 
